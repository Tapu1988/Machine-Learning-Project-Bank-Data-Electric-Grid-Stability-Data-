{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3881b46f-8a5d-49c3-98a9-719a4bded927",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2000b72-a223-4b93-904a-b4514ba84bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92dfa0d3-9421-4e7a-ba77-43609a29ccb5",
   "metadata": {},
   "source": [
    "# Part A: Logistic Regression (Bank Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52f324a7-bed2-40b5-a6e6-4db760848f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e01b31ec-447e-42ee-bb30-7214b9602716",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_zip_path = r\"C:\\\\Users\\DELL\\\\Downloads\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24f446de-e304-4798-955a-77c7bcb665ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files found: []\n"
     ]
    }
   ],
   "source": [
    "# Find CSV files inside the extracted nested zip\n",
    "csv_dir = '/mnt/data/bank_nested_extracted'\n",
    "csv_files = [f for f in os.listdir(csv_dir) if f.endswith('.csv')]\n",
    "print(\"CSV files found:\", csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db0157ac-6200-4ce2-ad2a-be80280d7a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CSV files found:\n",
      "/mnt/data/bank_nested_extracted\\bank-additional\\bank-additional-full.csv\n",
      "/mnt/data/bank_nested_extracted\\bank-additional\\bank-additional.csv\n"
     ]
    }
   ],
   "source": [
    "csv_dir = '/mnt/data/bank_nested_extracted'\n",
    "\n",
    "# Recursively find all CSV files\n",
    "csv_files = []\n",
    "for root, dirs, files in os.walk(csv_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            full_path = os.path.join(root, file)\n",
    "            csv_files.append(full_path)\n",
    "\n",
    "print(\" CSV files found:\")\n",
    "for f in csv_files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0522a63f-b4a7-47de-90ae-6a70bc1bb9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age        job  marital    education  default housing loan    contact  \\\n",
      "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
      "1   57   services  married  high.school  unknown      no   no  telephone   \n",
      "2   37   services  married  high.school       no     yes   no  telephone   \n",
      "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
      "4   56   services  married  high.school       no      no  yes  telephone   \n",
      "\n",
      "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
      "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
      "\n",
      "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
      "0          93.994          -36.4      4.857       5191.0  no  \n",
      "1          93.994          -36.4      4.857       5191.0  no  \n",
      "2          93.994          -36.4      4.857       5191.0  no  \n",
      "3          93.994          -36.4      4.857       5191.0  no  \n",
      "4          93.994          -36.4      4.857       5191.0  no  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Corrected path\n",
    "csv_path = '/mnt/data/bank_nested_extracted/bank-additional/bank-additional-full.csv'\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(csv_path, sep=';')\n",
    "\n",
    "# Show first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f41d0a4-69ce-4f05-b4c1-7a731a5a4be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32807655-15cd-4dcf-9694-947e5166599f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41188, 21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "482fd25c-28cb-4a86-a3cf-89fa9b8fe7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31989734-e8fd-4925-b1aa-459b9c91d338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>41188.00000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "      <td>41188.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.02406</td>\n",
       "      <td>258.285010</td>\n",
       "      <td>2.567593</td>\n",
       "      <td>962.475454</td>\n",
       "      <td>0.172963</td>\n",
       "      <td>0.081886</td>\n",
       "      <td>93.575664</td>\n",
       "      <td>-40.502600</td>\n",
       "      <td>3.621291</td>\n",
       "      <td>5167.035911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.42125</td>\n",
       "      <td>259.279249</td>\n",
       "      <td>2.770014</td>\n",
       "      <td>186.910907</td>\n",
       "      <td>0.494901</td>\n",
       "      <td>1.570960</td>\n",
       "      <td>0.578840</td>\n",
       "      <td>4.628198</td>\n",
       "      <td>1.734447</td>\n",
       "      <td>72.251528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.400000</td>\n",
       "      <td>92.201000</td>\n",
       "      <td>-50.800000</td>\n",
       "      <td>0.634000</td>\n",
       "      <td>4963.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32.00000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.800000</td>\n",
       "      <td>93.075000</td>\n",
       "      <td>-42.700000</td>\n",
       "      <td>1.344000</td>\n",
       "      <td>5099.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38.00000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>93.749000</td>\n",
       "      <td>-41.800000</td>\n",
       "      <td>4.857000</td>\n",
       "      <td>5191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.00000</td>\n",
       "      <td>319.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>93.994000</td>\n",
       "      <td>-36.400000</td>\n",
       "      <td>4.961000</td>\n",
       "      <td>5228.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>98.00000</td>\n",
       "      <td>4918.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>94.767000</td>\n",
       "      <td>-26.900000</td>\n",
       "      <td>5.045000</td>\n",
       "      <td>5228.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age      duration      campaign         pdays      previous  \\\n",
       "count  41188.00000  41188.000000  41188.000000  41188.000000  41188.000000   \n",
       "mean      40.02406    258.285010      2.567593    962.475454      0.172963   \n",
       "std       10.42125    259.279249      2.770014    186.910907      0.494901   \n",
       "min       17.00000      0.000000      1.000000      0.000000      0.000000   \n",
       "25%       32.00000    102.000000      1.000000    999.000000      0.000000   \n",
       "50%       38.00000    180.000000      2.000000    999.000000      0.000000   \n",
       "75%       47.00000    319.000000      3.000000    999.000000      0.000000   \n",
       "max       98.00000   4918.000000     56.000000    999.000000      7.000000   \n",
       "\n",
       "       emp.var.rate  cons.price.idx  cons.conf.idx     euribor3m   nr.employed  \n",
       "count  41188.000000    41188.000000   41188.000000  41188.000000  41188.000000  \n",
       "mean       0.081886       93.575664     -40.502600      3.621291   5167.035911  \n",
       "std        1.570960        0.578840       4.628198      1.734447     72.251528  \n",
       "min       -3.400000       92.201000     -50.800000      0.634000   4963.600000  \n",
       "25%       -1.800000       93.075000     -42.700000      1.344000   5099.100000  \n",
       "50%        1.100000       93.749000     -41.800000      4.857000   5191.000000  \n",
       "75%        1.400000       93.994000     -36.400000      4.961000   5228.100000  \n",
       "max        1.400000       94.767000     -26.900000      5.045000   5228.100000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f147150-ad30-4617-9f18-1471d8493250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Display the number of missing entries for each column\n",
    "missing_counts = df.isnull().sum()\n",
    "\n",
    "# Print feature names with missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_counts[missing_counts > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f30174-8a44-43ff-80f6-69ce3d2e6baa",
   "metadata": {},
   "source": [
    "##### There is no missing values in this Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d930fb87-8e2a-46b8-8d1b-6cdf090489ea",
   "metadata": {},
   "source": [
    "### Understand the Target Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "940b2964-41cd-4c57-a258-1d5c6916f74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts:\n",
      "y\n",
      "no     36548\n",
      "yes     4640\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Proportions:\n",
      "y\n",
      "no     0.887346\n",
      "yes    0.112654\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check unique values in target\n",
    "print(\"Value counts:\")\n",
    "print(df['y'].value_counts())\n",
    "print(\"\\nProportions:\")\n",
    "print(df['y'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8f5e0b-a430-4e0d-995f-5d0c6e60dce5",
   "metadata": {},
   "source": [
    "#### The target is y, which indicates if the client subscribed to a term deposit (yes or no)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5539f941-0366-455c-83da-0596c47101c8",
   "metadata": {},
   "source": [
    "### Preprocess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd21c05-7be1-4507-b8a3-bf44e2c4b47e",
   "metadata": {},
   "source": [
    "##### Encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71aef3fa-491b-443c-9ca7-4387f82c65d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db825e64-69ca-4197-8c2c-a265d7b53cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target\n",
    "df['y'] = df['y'].map({'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c7ee907-7f21-459f-a790-ecc5aef1f9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop('y', axis=1)\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2235a1b8-31a2-4dd4-a5d4-2781868876d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical variables\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9aa984c-e9ae-4d87-8629-566556acf73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad4d3bf8-38db-463e-ac18-fb72497c7768",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca950e3-3255-41c9-bec1-7629d4ca8041",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e296e8d5-89e2-4d6b-9876-ce446e47fa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "767a805f-72b5-4750-b0b3-d70c6f407217",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c518e088-dc47-4cad-95d1-5633179a2bbe",
   "metadata": {},
   "source": [
    "###  1. Build and Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95bde94f-01ff-47a8-bfd3-dd21f128e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83bc1497-e91d-4e0d-8b86-f427f1061ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f341379b-df0b-4544-9a7d-c9735a38f573",
   "metadata": {},
   "source": [
    "#### 2. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef76a531-9b54-4c6c-841b-b93ced15884c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Classification Report for train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     29238\n",
      "           1       0.66      0.42      0.51      3712\n",
      "\n",
      "    accuracy                           0.91     32950\n",
      "   macro avg       0.79      0.69      0.73     32950\n",
      "weighted avg       0.90      0.91      0.90     32950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_train)\n",
    "\n",
    "print(\" Classification Report for train:\")\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9fb216b-fff0-433a-b26b-6b63ef439488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Classification Report for test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95      7310\n",
      "           1       0.71      0.44      0.54       928\n",
      "\n",
      "    accuracy                           0.92      8238\n",
      "   macro avg       0.82      0.71      0.75      8238\n",
      "weighted avg       0.91      0.92      0.91      8238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\" Classification Report for test:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464adae4-4abd-4cc2-80d4-0d33c14cc2b7",
   "metadata": {},
   "source": [
    "### 1. Accuracy\n",
    "The proportion of total correct predictions.\n",
    "\n",
    "Train Accuracy: 0.91 (91%)\n",
    "\n",
    "Test Accuracy: 0.92 (92%)\n",
    "\n",
    "#### Interpretation:\n",
    "The model is performing consistently on both train and test sets. That’s a good sign — no major overfitting or underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f755bbec-ecaf-4a9a-9d70-62a5c3353916",
   "metadata": {},
   "source": [
    "## 2. Precision\n",
    "Out of all the positive predictions (yes to term deposit), how many were correct?\n",
    "\n",
    "Train Precision (Class 1): 0.66\n",
    "\n",
    "Test Precision (Class 1): 0.71\n",
    "\n",
    "#### Interpretation:\n",
    "About 66–71% of the predicted \"yes\" outcomes were correct. This is moderate. Precision is important when false positives are costly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13a2232-fa5f-4e2f-bc90-635087a8b0a0",
   "metadata": {},
   "source": [
    "### 3. Recall\n",
    "Out of all actual positives (yes), how many did the model correctly identify?\n",
    "\n",
    "Train Recall (Class 1): 0.42\n",
    "\n",
    "Test Recall (Class 1): 0.44\n",
    "\n",
    "####  Interpretation:\n",
    "The model only captures 44% of the actual \"yes\" cases. This is low recall, which means the model misses many potential subscribers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711393df-0e9f-4739-be6f-c2f7f5ef5a56",
   "metadata": {},
   "source": [
    "### 4. F1-Score\n",
    "Harmonic mean of precision and recall (good summary when classes are imbalanced)\n",
    "\n",
    "Train F1-Score (Class 1): 0.51\n",
    "\n",
    "Test F1-Score (Class 1): 0.54\n",
    "\n",
    "#### Interpretation:\n",
    "F1-score is moderate, indicating a tradeoff between precision and recall. Still, it reflects that the model struggles with identifying the minority class (yes to subscription)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004df463-fe2e-45a8-977d-2c0d4e15e807",
   "metadata": {},
   "source": [
    "### Observation\n",
    "The dataset is imbalanced — far more \"no\" than \"yes\" cases.\n",
    "\n",
    "Model performs well on the majority class, but not on the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae48edb1-569c-46b6-a647-24ba7131ee8f",
   "metadata": {},
   "source": [
    "# 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2954879f-729e-4d66-bae3-7cca9c149747",
   "metadata": {},
   "source": [
    "Here I use two types of regularization:\n",
    "\n",
    "L1 Regularization – Lasso (feature selection effect)\n",
    "\n",
    "L2 Regularization – Ridge (prevents overfitting)\n",
    "\n",
    "Here use the same X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7516c8a2-f9aa-4c81-8db3-98ef41843eb4",
   "metadata": {},
   "source": [
    "####  L1-Regularized Logistic Regression (Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8dd0e5e3-b2df-419c-91a9-63348b90329d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L1 Regularization\n",
    "model_l1 = LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000)\n",
    "model_l1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5914af71-96ae-4107-a5c0-eff225c58dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " L1-Regularized Logistic Regression (Lasso) for train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     29238\n",
      "           1       0.66      0.42      0.51      3712\n",
      "\n",
      "    accuracy                           0.91     32950\n",
      "   macro avg       0.79      0.69      0.73     32950\n",
      "weighted avg       0.90      0.91      0.90     32950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions for train\n",
    "y_pred_l1 = model_l1.predict(X_train)\n",
    "\n",
    "# Evaluation\n",
    "print(\" L1-Regularized Logistic Regression (Lasso) for train\")\n",
    "print(classification_report(y_train, y_pred_l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c574387-d12a-4adf-9a3d-1fe04c63af60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " L1-Regularized Logistic Regression (Lasso) for test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95      7310\n",
      "           1       0.71      0.44      0.54       928\n",
      "\n",
      "    accuracy                           0.92      8238\n",
      "   macro avg       0.82      0.71      0.75      8238\n",
      "weighted avg       0.91      0.92      0.91      8238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions for test\n",
    "y_pred_l1 = model_l1.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\" L1-Regularized Logistic Regression (Lasso) for test\")\n",
    "print(classification_report(y_test, y_pred_l1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b60af6-e160-4016-9fd6-7d4ea1278132",
   "metadata": {},
   "source": [
    "###  L2-Regularized Logistic Regression (Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14a6b34c-d6cf-4b0e-bc60-98f91c6260d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, solver='liblinear')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L2 Regularization\n",
    "model_l2 = LogisticRegression(penalty='l2', solver='liblinear', max_iter=1000)\n",
    "model_l2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24344a60-1601-4a58-ba86-fae5ae55a2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " L2-Regularized Logistic Regression (Ridge) for train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     29238\n",
      "           1       0.66      0.42      0.51      3712\n",
      "\n",
      "    accuracy                           0.91     32950\n",
      "   macro avg       0.79      0.69      0.73     32950\n",
      "weighted avg       0.90      0.91      0.90     32950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions for train\n",
    "y_pred_l2 = model_l2.predict(X_train)\n",
    "\n",
    "# Evaluation\n",
    "print(\" L2-Regularized Logistic Regression (Ridge) for train\")\n",
    "print(classification_report(y_train, y_pred_l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25367612-f3af-4e2c-a4e3-054dcc342064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " L2-Regularized Logistic Regression (Ridge) for test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95      7310\n",
      "           1       0.71      0.44      0.54       928\n",
      "\n",
      "    accuracy                           0.92      8238\n",
      "   macro avg       0.82      0.71      0.75      8238\n",
      "weighted avg       0.91      0.92      0.91      8238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions for test\n",
    "y_pred_l2 = model_l2.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\" L2-Regularized Logistic Regression (Ridge) for test\")\n",
    "print(classification_report(y_test, y_pred_l2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a2db2b-9203-4329-9654-68f59f856332",
   "metadata": {},
   "source": [
    "## Key Inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd40d28a-13fb-457c-aa01-9e425d811445",
   "metadata": {},
   "source": [
    "#### 1. Overall Accuracy is High for Both Models\n",
    "L1: 92%, L2: 92% — Both models perform well overall, but this is mostly due to correctly predicting the majority class (\"no\").\n",
    "\n",
    "#### 2. Minority Class (yes) Detection is Still Weak\n",
    "Recall (Class 1):\n",
    "\n",
    "L1: 44%\n",
    "\n",
    "L2: 44%\n",
    "\n",
    "This shows that both models struggle to detect actual \"yes\" responses.\n",
    "\n",
    "#### 3. Precision & F1-Score Slightly Better in L1\n",
    "Precision (Class 1):\n",
    "\n",
    "L1: 0.71 | L2: 0.71\n",
    "\n",
    "F1-Score (Class 1):\n",
    "\n",
    "L1: 0.54 | L2: 0.54\n",
    "\n",
    "These values suggest that both L1 and L2 regularization are same effective at identifying potential subscribers.\n",
    "\n",
    "#### 4. L1 Regularization Offers Feature Selection\n",
    "L1 can shrink some coefficients to zero, simplifying the model and potentially improving generalization.\n",
    "\n",
    "May help identify key influencing features for subscription decisions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7b8168-8173-42aa-b197-21ba6be6aadb",
   "metadata": {},
   "source": [
    "# 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede5f518-8cff-4c81-9408-3e60370be5b1",
   "metadata": {},
   "source": [
    "Here I compare the models on the following criteria:\n",
    "\n",
    "1. Number of trainable parameters\n",
    "\n",
    "2. Training time\n",
    "\n",
    "3. Model performance (Accuracy, Precision, Recall, F1-score)\n",
    "\n",
    "4. Why KNN is better/worse than Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93705a6d-4d3b-4bc4-be1e-66cea121f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73190a4b-076b-442b-aae8-e1585b4677a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "start_logreg = time.time()\n",
    "logreg = LogisticRegression(penalty='l2', solver='liblinear')\n",
    "logreg.fit(X_train, y_train)\n",
    "end_logreg = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1816189e-1408-4424-bb81-4b5983816c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_logreg = logreg.predict(X_test)\n",
    "report_logreg = classification_report(y_test, y_pred_logreg, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28aa51ed-0116-45c0-9859-980f04400fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Classifier\n",
    "start_knn = time.time()\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "end_knn = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d64e53b9-ccb7-49da-9ac8-e2aec059046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn = knn.predict(X_test)\n",
    "report_knn = classification_report(y_test, y_pred_knn, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6e3eb5a-2ecf-475c-bd5a-8c22b9f8ac12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model Performance Comparison:\n",
      "           Metric  Logistic Regression     KNN\n",
      "0        Accuracy               0.9164  0.9022\n",
      "1   Precision (1)               0.7093  0.6173\n",
      "2      Recall (1)               0.4364  0.3459\n",
      "3    F1-score (1)               0.5404  0.4434\n",
      "4  Train Time (s)               0.8717  0.0060\n"
     ]
    }
   ],
   "source": [
    "# Comparison Table\n",
    "comparison = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision (1)', 'Recall (1)', 'F1-score (1)', 'Train Time (s)'],\n",
    "    'Logistic Regression': [\n",
    "        report_logreg['accuracy'],\n",
    "        report_logreg['1']['precision'],\n",
    "        report_logreg['1']['recall'],\n",
    "        report_logreg['1']['f1-score'],\n",
    "        end_logreg - start_logreg\n",
    "    ],\n",
    "    'KNN': [\n",
    "        report_knn['accuracy'],\n",
    "        report_knn['1']['precision'],\n",
    "        report_knn['1']['recall'],\n",
    "        report_knn['1']['f1-score'],\n",
    "        end_knn - start_knn\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n Model Performance Comparison:\")\n",
    "print(comparison.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3904af84-a391-4f3f-9191-754e70f63937",
   "metadata": {},
   "source": [
    "## Interpretation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b6aa21-4d1e-4876-8cee-efe9944553e5",
   "metadata": {},
   "source": [
    "#### 1.  Model Performance\n",
    "Logistic Regression performs better across all classification metrics for the positive class (y = 1 → term deposit = yes):\n",
    "\n",
    "Higher precision means fewer false positives (better targeting).\n",
    "\n",
    "Higher recall means it finds more actual positive cases (better customer conversion).\n",
    "\n",
    "Higher F1-score confirms a better balance between precision and recall.\n",
    "\n",
    "#### Conclusion: Logistic Regression is more effective at identifying customers likely to subscribe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce74a75-b38d-40c4-a70d-023ae6aecf92",
   "metadata": {},
   "source": [
    "#### 2.  Training Time\n",
    "KNN is much faster to train (almost instant), because it doesn’t learn any weights — it just stores the data.\n",
    "\n",
    "Logistic Regression takes longer (about 0.92 seconds) due to weight optimization via gradient descent.\n",
    "\n",
    "##### Conclusion: KNN is faster to train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160b13c6-2905-469f-b138-51538be89006",
   "metadata": {},
   "source": [
    "### Final Conclusion:\n",
    "Logistic Regression is better than KNN on this dataset because it generalizes well, handles feature scaling and imbalance effectively, and offers higher predictive performance.\n",
    "\n",
    "While KNN is faster to train and easy to implement, it suffers from poorer recall and F1-score, making it less suitable for this business use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8fa6d0-3a45-45cd-855e-be4b7b27b8e5",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e144568-c38e-4a02-befa-f23796508b66",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f506d2df-256a-4064-b6a2-64f485038f0a",
   "metadata": {},
   "source": [
    "# Part B: SVM Classification (Grid Stability Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cfac7f-2b85-4bbb-b400-3d60030d6c03",
   "metadata": {},
   "source": [
    "# 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52e567f7-9c3c-43da-8d7d-ca71c1b02302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\DELL'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c55f06a5-353e-476e-a03e-31c68e4c174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chainge the path of data set\n",
    "os.chdir(\"Downloads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37bf86ce-5b80-4a1d-b28a-d84569e72433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the zip file\n",
    "\n",
    "with zipfile.ZipFile('electrical+grid+stability+simulated+data.zip', 'r') as zip_ref:\n",
    "\n",
    "    # Extract the csv.gz file\n",
    "\n",
    "    csv_file_name = \"Data_for_UCI_named.csv\"  \n",
    "\n",
    "    zip_ref.extract(csv_file_name)\n",
    "    \n",
    "     # Read the CSV data using pandas\n",
    "\n",
    "    df1 = pd.read_csv(\"Data_for_UCI_named.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad302ef6-aac6-48e6-a068-4cc0e7df79b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>-0.005957</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>0.049860</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0  2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1  9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2  8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3  0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4  3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "\n",
       "         p4        g1        g2        g3        g4      stab     stabf  \n",
       "0 -1.723086  0.650456  0.859578  0.887445  0.958034  0.055347  unstable  \n",
       "1 -1.255012  0.413441  0.862414  0.562139  0.781760 -0.005957    stable  \n",
       "2 -0.920492  0.163041  0.766689  0.839444  0.109853  0.003471  unstable  \n",
       "3 -0.997374  0.446209  0.976744  0.929381  0.362718  0.028871  unstable  \n",
       "4 -0.554305  0.797110  0.455450  0.656947  0.820923  0.049860  unstable  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c0b870a-a404-4405-bfd6-637e1fd947c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (rows, columns): (10000, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape (rows, columns):\", df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c0b49ce-3bf4-4cc4-8447-2f8941ef657a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   tau1    10000 non-null  float64\n",
      " 1   tau2    10000 non-null  float64\n",
      " 2   tau3    10000 non-null  float64\n",
      " 3   tau4    10000 non-null  float64\n",
      " 4   p1      10000 non-null  float64\n",
      " 5   p2      10000 non-null  float64\n",
      " 6   p3      10000 non-null  float64\n",
      " 7   p4      10000 non-null  float64\n",
      " 8   g1      10000 non-null  float64\n",
      " 9   g2      10000 non-null  float64\n",
      " 10  g3      10000 non-null  float64\n",
      " 11  g4      10000 non-null  float64\n",
      " 12  stab    10000 non-null  float64\n",
      " 13  stabf   10000 non-null  object \n",
      "dtypes: float64(13), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0593bd2f-ae81-4c6f-8815-c923a0be859e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Display the number of missing entries for each column\n",
    "missing_counts = df1.isnull().sum()\n",
    "\n",
    "# Print feature names with missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_counts[missing_counts > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6003ebb-942e-4cfd-87ff-6beb06a9835f",
   "metadata": {},
   "source": [
    "# 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3bfa424d-1340-4110-81f9-b4a722d42c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8572237-92c8-4e24-8c17-ea744a77c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable\n",
    "df1['stabf'] = LabelEncoder().fit_transform(df1['stabf'])  # stable=1, unstable=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76e06310-00c8-41b3-962d-4f860d4d3853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X = df1.drop('stabf', axis=1)\n",
    "y = df1['stabf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41d7bf5d-c460-4d55-ab2e-b4989c84cc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bebd9f5b-5ebd-411f-b193-1aa4d287f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3dc5572c-0465-4038-93db-4deb915e9987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SVM with linear kernel:\n",
      " Classification Report for Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2896\n",
      "           1       1.00      1.00      1.00      5104\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       1.00      1.00      1.00      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      " Classification Report for Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       724\n",
      "           1       1.00      1.00      1.00      1276\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       0.99      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "\n",
      " SVM with rbf kernel:\n",
      " Classification Report for Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      2896\n",
      "           1       0.99      1.00      1.00      5104\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       1.00      0.99      0.99      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n",
      " Classification Report for Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       724\n",
      "           1       0.99      0.99      0.99      1276\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       0.99      0.99      0.99      2000\n",
      "weighted avg       0.99      0.99      0.99      2000\n",
      "\n",
      "\n",
      " SVM with poly kernel:\n",
      " Classification Report for Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97      2896\n",
      "           1       0.98      0.99      0.98      5104\n",
      "\n",
      "    accuracy                           0.98      8000\n",
      "   macro avg       0.98      0.98      0.98      8000\n",
      "weighted avg       0.98      0.98      0.98      8000\n",
      "\n",
      " Classification Report for Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       724\n",
      "           1       0.98      0.99      0.98      1276\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.98      0.97      0.97      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and Evaluate SVM Models with Different Kernels\n",
    "kernels = ['linear', 'rbf', 'poly']\n",
    "for kernel in kernels:\n",
    "    print(f\"\\n SVM with {kernel} kernel:\")\n",
    "    \n",
    "    model = SVC(kernel=kernel)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions for Train set\n",
    "    y_pred_train = model.predict(X_train_scaled)\n",
    "    print(\" Classification Report for Train:\")\n",
    "    print(classification_report(y_train, y_pred_train))\n",
    "    \n",
    "    # Predictions for Test set\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "    print(\" Classification Report for Test:\")\n",
    "    print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2fa4fc82-185f-41fd-a07b-0a3c1a3ae47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f81e7885-bf6a-4756-b1f1-31e978f1e4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SVM with linear kernel...\n",
      "\n",
      "Training SVM with rbf kernel...\n",
      "\n",
      "Training SVM with poly kernel...\n",
      "\n",
      " SVM Kernel Comparison Table:\n",
      "\n",
      "   Kernel  Accuracy  Precision  Recall  F1-score  Train Time (s)  \\\n",
      "0  linear      1.00       1.00    1.00      1.00            0.34   \n",
      "1     rbf      0.99       0.99    0.99      0.99            0.67   \n",
      "2    poly      0.98       0.98    0.99      0.98            0.83   \n",
      "\n",
      "                            Used Hyperparameters  \n",
      "0                         C=1.0, kernel='linear'  \n",
      "1             C=1.0, kernel='rbf', gamma='scale'  \n",
      "2  C=1.0, kernel='poly', degree=3, gamma='scale'  \n"
     ]
    }
   ],
   "source": [
    "# Initialize list to store results\n",
    "results = []\n",
    "\n",
    "# Define kernels to compare\n",
    "kernels = ['linear', 'rbf', 'poly']\n",
    "\n",
    "# Loop through kernels and evaluate\n",
    "for kernel in kernels:\n",
    "    print(f\"\\nTraining SVM with {kernel} kernel...\")\n",
    "    \n",
    "    model = SVC(kernel=kernel)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "# Collect metrics for test set\n",
    "    accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    precision = precision_score(y_test, y_pred_test, pos_label= 1)\n",
    "    recall = recall_score(y_test, y_pred_test, pos_label= 1)\n",
    "    f1 = f1_score(y_test, y_pred_test, pos_label= 1)\n",
    " \n",
    "# Append to results\n",
    "    results.append({\n",
    "        'Kernel': kernel,\n",
    "        'Accuracy': round(accuracy, 2),\n",
    "        'Precision': round(precision, 2),\n",
    "        'Recall': round(recall, 2),\n",
    "        'F1-score': round(f1, 2),\n",
    "        'Train Time (s)': round(train_time, 2),\n",
    "        'Used Hyperparameters': f\"C=1.0, kernel='{kernel}'\" +\n",
    "                                (\", degree=3\" if kernel == 'poly' else \"\") +\n",
    "                                (\", gamma='scale'\" if kernel in ['rbf', 'poly'] else \"\")\n",
    "    })\n",
    "\n",
    "# Create a DataFrame for comparison\n",
    "comparison_df = pd.DataFrame(results)\n",
    "print(\"\\n SVM Kernel Comparison Table:\\n\")\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85181e3-026a-48ec-a1a4-9d752e3cf079",
   "metadata": {},
   "source": [
    "### Key Inferences\n",
    "##### 1. Linear Kernel\n",
    "Best overall performance: Achieves perfect accuracy on both train and test.\n",
    "\n",
    "No signs of overfitting: High train and test accuracy/f1-scores are matched.\n",
    "\n",
    "Interpretability: Linear SVM is easier to interpret and faster to train.\n",
    "\n",
    "##### Inference: The data is likely linearly separable, making the linear kernel ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6017233a-b85d-4bb7-8c5e-019f5f3ff434",
   "metadata": {},
   "source": [
    "### 2. RBF Kernel\n",
    "Still performs very well, with near-perfect results (99% accuracy).\n",
    "\n",
    "Slight drop in recall for class 0 (0.98 vs. 0.99), but minor.\n",
    "\n",
    "More complex model than linear.\n",
    "\n",
    "##### Inference: Adds flexibility, but doesn’t significantly improve results — possibly unnecessary complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08405e8b-a226-4b3c-b55d-1e0849ad5d38",
   "metadata": {},
   "source": [
    "#### 3. Polynomial Kernel\n",
    "Slightly worse performance than linear and RBF on both train and test.\n",
    "\n",
    "Recall for class 0 (0.98) is lowest among all three.\n",
    "\n",
    "More prone to overfitting due to increased complexity, especially with higher-degree polynomials.\n",
    "\n",
    "##### Inference: Polynomial decision boundaries don’t match the structure of this data well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cfb1f7-441d-45dd-a6b9-6be2809789c9",
   "metadata": {},
   "source": [
    "# 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64be40de-ed72-4ff2-ba82-069482647705",
   "metadata": {},
   "source": [
    "## Hyper-parameters of SVM (C Tuning Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f3895ea9-d718-4d7e-b099-dc80e0eb70bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e51b4f0c-d140-4fdc-8f15-c6fa0ff15b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tuning C for linear kernel...\n",
      "\n",
      " Tuning C for rbf kernel...\n",
      "\n",
      " Tuning C for poly kernel...\n",
      "\n",
      " Best Performance After C Tuning:\n",
      "\n",
      "   Kernel  Best C  Accuracy  Precision  Recall  F1-score\n",
      "0  linear     100      1.00       1.00    1.00      1.00\n",
      "1     rbf       1      0.99       0.99    0.99      0.99\n",
      "2    poly      10      0.98       0.99    0.98      0.98\n"
     ]
    }
   ],
   "source": [
    "# C values to search\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "# Store best results\n",
    "tuning_results = []\n",
    "\n",
    "for kernel in ['linear', 'rbf', 'poly']:\n",
    "    print(f\"\\n Tuning C for {kernel} kernel...\")\n",
    "    \n",
    "    param_grid = {'C': C_values}\n",
    "    \n",
    "    # Use default values for other params\n",
    "    svc = SVC(kernel=kernel)\n",
    "    \n",
    "    grid = GridSearchCV(svc, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    best_model = grid.best_estimator_\n",
    "    best_params = grid.best_params_\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    tuning_results.append({\n",
    "        'Kernel': kernel,\n",
    "        'Best C': best_params['C'],\n",
    "        'Accuracy': round(acc, 2),\n",
    "        'Precision': round(prec, 2),\n",
    "        'Recall': round(rec, 2),\n",
    "        'F1-score': round(f1, 2)\n",
    "    })\n",
    "\n",
    "#  Show results\n",
    "tuned_df = pd.DataFrame(tuning_results)\n",
    "print(\"\\n Best Performance After C Tuning:\\n\")\n",
    "print(tuned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758b1551-316d-4523-80c1-5408335befab",
   "metadata": {},
   "source": [
    "# 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6484e3ce-e2a8-4a59-b98a-18c5ad518451",
   "metadata": {},
   "source": [
    "##  Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2795cd96-6c1a-4ce9-a013-81792a2d39aa",
   "metadata": {},
   "source": [
    "#### 1. Linear Kernel (Best C = 100)\n",
    ". Achieved perfect classification (Accuracy = 1.00) on the test set.\n",
    "\n",
    ". The fact that a linear kernel performs best even with high C suggests that:\n",
    "\n",
    ". The data is linearly separable, and\n",
    "\n",
    ". A higher regularization penalty (C = 100) helped reduce bias and perfectly fit the decision boundary.\n",
    "\n",
    ". Best choice in terms of both performance and training speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cbe374-e3c8-4d8c-b29f-a57e5f17f1b2",
   "metadata": {},
   "source": [
    "#### 2. RBF Kernel (Best C = 1)\n",
    ". Also performed very well, with slightly lower scores than linear.\n",
    "\n",
    ". The best performance was achieved at C = 1, which indicates that:\n",
    "\n",
    ". A moderate trade-off between margin width and classification accuracy was optimal.\n",
    "\n",
    ". There was no need for high complexity in the decision boundary.\n",
    "\n",
    ". RBF did not outperform linear — confirming the linear separability of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf2e052-2fca-4070-955e-28387c37a6ff",
   "metadata": {},
   "source": [
    "#### 3. Polynomial Kernel (Best C = 10)\n",
    ". Slightly lower performance compared to linear and RBF.\n",
    "\n",
    ". Polynomial models are more complex and can overfit when C is high, which might explain the slight drop in performance.\n",
    "\n",
    ". Still very good, but no clear benefit over simpler kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c069dc81-b341-451b-bf61-ee0809dc462a",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6df431-bbe4-4b54-a266-2ad405bdc708",
   "metadata": {},
   "source": [
    ". Linear kernel with C = 100 is the best performing model — achieving perfect generalization.\n",
    "\n",
    ". RBF and poly kernels add unnecessary complexity for this dataset.\n",
    "\n",
    ". Since training time and interpretability matter in real-world applications, the linear SVM is both the most efficient and accurate solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2883f699-b035-4fe4-9405-0545f2c70a07",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdd1578-159d-443f-a6f9-f103fa82b64a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
